{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing \n",
    "- Tokenization\n",
    "- Stemming and Lemmatization\n",
    "- StopWords\n",
    "- POS: Parts of Speech tagging is a linguistic activity in Natural Language Processing (NLP) wherein each word in a document is given a particular part of speech (adverb, adjective, verb, etc.) or grammatical category.\n",
    "- BOW (Bag Of Words)\n",
    "- TF-IDF\n",
    "- Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "In Text Preprocessing 1, we discussed BOW (bag of words) and TF-IDF approach, however, semantic information is not stored in thoese methods. And thereâ€™s chance of overfitting. To overcome these problems, we have the Word2Vec model.\n",
    "\n",
    "In Word2Vec, each word is represented as a vector of 32 or more dimension instead of a single number. The semantic information and relation between different words is also preserved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## review for granger down wash from Amazon\n",
    "paragraph = \"\"\"You should know two things about using this product: it takes over four hours from start to finish to clean a down jacket right, and this is not your usual casual laundry.\n",
    "\n",
    "I own the Patagonia Primo ski jacket. 800 count down, three ply Gore-Tex. I did not want to screw it up. Here in Chicago, a warm waterproof jacket literally keeps me alive while working outside in the winter. I cannot afford (in all meanings of the word) for my winter coat to fail.\n",
    "\n",
    "I did a lot of research before I put it in the wash with this cleaner. I can say it works well; the down is as lofty as new, the Gore-Tex unaffected, and the Durable Water Resistance (DWR) renewed.\n",
    "\n",
    "I took several steps the ensure success, based on advice from the Arcteryx clothing YouTube channel, Patagonia's site and clothing label, and other sources.\n",
    "\n",
    "First, I ran my washing machine empty, normal wash, hot water, to get all detergent residue out. Regular detergents have enzymes that can damage down; you don't want it in your coat.\n",
    "\n",
    "I zipped my main zipper closed (always a good thing to do in any case), and closed my pocket zippers halfway, to protect them but yet allow the pockets to get clean. Ditto my pit zips.\n",
    "\n",
    "I loosened all cord locks so the hood and waist were fully relaxed and opened.\n",
    "\n",
    "I set my Velcro cuffs to their widest.\n",
    "\n",
    "I washed the coat with two caps of cleaner, with the machine set for delicates, warm water, gentle spin.\n",
    "\n",
    "When it was completed I ran a rinse/spin cycle, cold water, gentle spin.\n",
    "\n",
    "The jacket was sopping wet when all that was done. I laid it flat on a beach towel, then gently rolled it up like a burrito, without squeezing or wringing, to remove excess water.\n",
    "\n",
    "Then, into the dryer, on low heat, with two tennis balls, as specified by Patagonia. I added a dry beach towel to help absorb the water; this seemed to speed thing up a bit, but I'd like to hear if people think this is a good or bad idea. I checked on it every half hour or so; I turned it inside out to facilitate the drying. It takes about three hours in the dryer to dry completely.\n",
    "\n",
    "Out of the dryer the loft was exceptional, and a little water dribbled on the coat ran right off without being absorbed, proving the DWR was renewed. I've taken it out in a moderate rain storm, and it's still waterproof.\n",
    "\n",
    "I hope these tips help you out. I'm pleased with the results I achieved.\n",
    "\n",
    "Winter is coming. Grangers has helped me get ready for it.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing \n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)\n",
    "text = re.sub(r'\\s+',' ',text) #replace any sequence of one or more whitespace characters (spaces, tabs, newlines, etc.) with space\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Word2Vec model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# Access vocabulary details\n",
    "words = model.wv.key_to_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': 0, '.': 1, 'water': 2, ';': 3, 'jacket': 4, 'coat': 5, 'dryer': 6, 'winter': 7, 'patagonia': 8, '(': 9, 'ran': 10, ')': 11, 'get': 12, 'two': 13, 'without': 14, 'like': 15, 'dry': 16, 'help': 17, 'towel': 18, 'wash': 19, 'thing': 20, 'beach': 21, 'renewed': 22, 'spin': 23, 'gentle': 24, 'set': 25, 'clothing': 26, \"'s\": 27, 'machine': 28, 'good': 29, 'closed': 30, 'dwr': 31, 'cleaner': 32, 'right': 33, 'warm': 34, 'hours': 35, 'three': 36, 'takes': 37, 'gore-tex': 38, 'want': 39, 'clean': 40, 'waterproof': 41, 'detergents': 42, 'label': 43, 'steps': 44, 'ensure': 45, 'success': 46, 'based': 47, 'advice': 48, 'start': 49, 'arcteryx': 50, 'damage': 51, 'youtube': 52, 'channel': 53, 'four': 54, 'site': 55, 'sources': 56, 'regular': 57, 'first': 58, 'things': 59, 'enzymes': 60, 'several': 61, ':': 62, 'empty': 63, 'using': 64, 'normal': 65, 'hot': 66, 'product': 67, 'detergent': 68, 'residue': 69, 'washing': 70, 'keeps': 71, 'finish': 72, 'took': 73, 'working': 74, 'outside': 75, 'literally': 76, 'afford': 77, 'meanings': 78, 'chicago': 79, 'word': 80, 'screw': 81, 'fail': 82, 'lot': 83, 'research': 84, 'put': 85, 'ply': 86, 'zipped': 87, 'say': 88, 'works': 89, 'count': 90, 'well': 91, 'ski': 92, 'primo': 93, 'laundry': 94, 'lofty': 95, 'new': 96, 'unaffected': 97, 'durable': 98, 'casual': 99, 'resistance': 100, 'usual': 101, 'alive': 102, \"n't\": 103, 'ready': 104, 'main': 105, 'drying': 106, 'inside': 107, 'turned': 108, 'hour': 109, 'half': 110, 'every': 111, 'checked': 112, 'idea': 113, 'bad': 114, 'think': 115, 'people': 116, 'hear': 117, \"'d\": 118, 'bit': 119, 'speed': 120, 'seemed': 121, 'absorb': 122, 'added': 123, 'specified': 124, 'balls': 125, 'facilitate': 126, 'completely': 127, 'heat': 128, 'loft': 129, 'grangers': 130, 'coming': 131, 'achieved': 132, 'results': 133, 'pleased': 134, \"'m\": 135, 'tips': 136, 'hope': 137, 'still': 138, 'storm': 139, 'rain': 140, 'moderate': 141, 'taken': 142, \"'ve\": 143, 'proving': 144, 'absorbed': 145, 'dribbled': 146, 'little': 147, 'exceptional': 148, 'tennis': 149, 'low': 150, 'zipper': 151, 'opened': 152, 'fully': 153, 'waist': 154, 'hood': 155, 'locks': 156, 'cord': 157, 'loosened': 158, 'zips': 159, 'pit': 160, 'ditto': 161, 'pockets': 162, 'allow': 163, 'yet': 164, 'protect': 165, 'halfway': 166, 'zippers': 167, 'pocket': 168, 'case': 169, 'helped': 170, 'always': 171, 'relaxed': 172, 'velcro': 173, 'excess': 174, 'cuffs': 175, 'remove': 176, 'wringing': 177, 'squeezing': 178, 'burrito': 179, 'rolled': 180, 'gently': 181, 'flat': 182, 'laid': 183, 'done': 184, 'wet': 185, 'sopping': 186, 'cold': 187, 'cycle': 188, 'rinse/spin': 189, 'completed': 190, 'delicates': 191, 'caps': 192, 'washed': 193, 'widest': 194, 'know': 195}\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Word Vectors\n",
    "vector = model.wv['water']\n",
    "\n",
    "# Most similar words\n",
    "similar = model.wv.most_similar('water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.4669449e-05  3.1122367e-03 -6.8130204e-03 -1.3196648e-03\n",
      "  7.6049580e-03  7.2199828e-03 -3.6538129e-03  2.7571912e-03\n",
      " -8.3689252e-03  6.1584376e-03 -4.6531884e-03 -3.2273859e-03\n",
      "  9.2729628e-03  9.2281576e-04  7.4480027e-03 -6.0846391e-03\n",
      "  5.1994571e-03  9.8198513e-03 -8.5367570e-03 -5.2658594e-03\n",
      " -7.0919800e-03 -4.8739729e-03 -3.7834318e-03 -8.5326703e-03\n",
      "  7.9363380e-03 -4.8710369e-03  8.4203435e-03  5.2250256e-03\n",
      " -6.6436008e-03  4.0003024e-03  5.4777670e-03 -7.4295225e-03\n",
      " -7.3083849e-03 -2.5296691e-03 -8.7129120e-03 -1.4305762e-03\n",
      " -3.9131049e-04  3.2640360e-03  1.4350056e-03 -1.0357924e-03\n",
      " -5.6137429e-03  1.6137923e-03 -9.8565349e-04  6.7918324e-03\n",
      "  4.0379530e-03  4.5901234e-03  1.4064645e-03 -2.7221863e-03\n",
      " -4.4015869e-03 -9.9315797e-04  1.4715518e-03 -2.6860726e-03\n",
      " -7.0302659e-03 -7.8357477e-03 -9.0995217e-03 -5.9431670e-03\n",
      " -1.8578147e-03 -4.3345988e-03 -6.5662628e-03 -3.7178348e-03\n",
      "  4.2760894e-03 -3.7415200e-03  8.4257452e-03  1.5076697e-03\n",
      " -7.3691774e-03  9.4890865e-03  7.7192970e-03  5.5786115e-03\n",
      " -6.9360388e-03  5.9291325e-03  4.0098974e-03  5.1888200e-03\n",
      "  4.2820475e-03  1.9477125e-03 -3.0923542e-03  8.4127523e-03\n",
      "  9.5814317e-03  3.7559790e-03 -2.9027418e-03 -2.2530574e-05\n",
      "  1.2298420e-03 -8.4530627e-03 -8.3021838e-03 -1.3799009e-04\n",
      "  1.1794615e-03 -5.7509150e-03 -4.6026795e-03 -7.2985543e-03\n",
      "  8.4011443e-03  1.3467748e-04 -4.4437787e-03  5.6991279e-03\n",
      "  9.2036827e-03 -4.0077772e-03  8.0717253e-03  5.4469206e-03\n",
      "  5.8863172e-03  4.6755016e-04  8.2419477e-03 -7.0856060e-03]\n"
     ]
    }
   ],
   "source": [
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('detergent', 0.3722821772098541), ('waterproof', 0.21293485164642334), ('hope', 0.20585587620735168), ('youtube', 0.20357394218444824), ('patagonia', 0.20141823589801788), ('remove', 0.20058925449848175), ('little', 0.19965402781963348), ('research', 0.18946188688278198), ('unaffected', 0.18259188532829285), (')', 0.1777937114238739)]\n"
     ]
    }
   ],
   "source": [
    "print(similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
